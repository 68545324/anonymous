{
  "buffer_size": 400000,
  "burn_in": 0,
  "callbacks": "<class 'submission.utils.callbacks.merge_callbacks.<locals>.MergedCallBacks'>",
  "double_q": true,
  "dueling": true,
  "env": "<class 'submission.envs.ssd_mixed_motive_coin_game.SSDMixedMotiveCoinGame'>",
  "env_config": {
    "beta_steps_config": [
      [
        0,
        0.125
      ],
      [
        1.0,
        0.25
      ]
    ],
    "both_players_can_pick_the_same_coin": true,
    "bs_epi_mul": 4,
    "buf_frac": 0.5,
    "grid_size": 3,
    "lr_steps_config": [
      [
        0,
        1.0
      ],
      [
        0.25,
        0.5
      ],
      [
        1.0,
        1e-09
      ]
    ],
    "max_steps": 100,
    "players_ids": [
      "player_red",
      "player_blue"
    ],
    "punishment_helped": true,
    "temperature_steps_config": [
      [
        0,
        0.75
      ],
      [
        0.2,
        0.45
      ],
      [
        0.9,
        0.00075
      ]
    ]
  },
  "exploration_config": {
    "temperature_schedule": "<ray.rllib.utils.schedules.piecewise_schedule.PiecewiseSchedule object at 0x7f3684212898>",
    "type": "<class 'submission.utils.exploration.SoftQSchedule'>"
  },
  "explore": true,
  "framework": "torch",
  "gamma": 0.96,
  "grad_clip": 1,
  "hiddens": [
    32
  ],
  "learning_starts": 400,
  "logger_config": {
    "wandb": {
      "api_key_file": "./../../../api_key_wandb",
      "group": "amTFT/2021_05_17/18_08_40",
      "log_config": true,
      "project": "amTFT"
    }
  },
  "lr": 0.1,
  "lr_schedule": "<ray.rllib.utils.schedules.piecewise_schedule.PiecewiseSchedule object at 0x7f36842127b8>",
  "min_iter_time_s": 0.0,
  "model": {
    "conv_filters": [
      [
        64,
        [
          3,
          3
        ],
        1
      ],
      [
        64,
        [
          3,
          3
        ],
        1
      ]
    ],
    "dim": 3,
    "fcnet_hiddens": [
      64,
      64
    ],
    "lstm_cell_size": 16,
    "max_seq_len": 20,
    "use_lstm": true
  },
  "multiagent": {
    "observation_fn": "<function observation_fn at 0x7f3687e8ab70>",
    "policies": {
      "player_blue": [
        "<class 'submission.algos.amTFT.policy_using_rollouts.AmTFTRolloutsTorchPolicy'>",
        "Box(0, 1, (3, 3, 6), uint8)",
        "Discrete(4)",
        {
          "auto_load_checkpoint": true,
          "batch_mode": "complete_episodes",
          "callbacks": null,
          "debit_threshold": 3.0,
          "last_k": 1,
          "n_rollout_replicas": 10,
          "nested_policies": [
            {
              "Policy_class": "<class 'ray.rllib.policy.policy_template.R2D2TorchPolicy'>",
              "config_update": {
                "add_inequity_aversion_welfare": [
                  true,
                  0.0,
                  "<ray.rllib.utils.schedules.piecewise_schedule.PiecewiseSchedule object at 0x7f3684212860>",
                  0.96,
                  0.96
                ],
                "add_utilitarian_welfare": false
              }
            },
            {
              "Policy_class": "<class 'ray.rllib.policy.policy_template.R2D2TorchPolicy'>",
              "config_update": {}
            },
            {
              "Policy_class": "<class 'ray.rllib.policy.policy_template.R2D2TorchPolicy'>",
              "config_update": {}
            },
            {
              "Policy_class": "<class 'ray.rllib.policy.policy_template.R2D2TorchPolicy'>",
              "config_update": {}
            }
          ],
          "opp_policy_id": "player_red",
          "optimizer": {
            "sgd_momentum": 0.9
          },
          "own_policy_id": "player_blue",
          "punish_instead_of_selfish": true,
          "punishment_multiplier": 6.0,
          "rollout_length": 20,
          "use_short_debit_rollout": true,
          "verbose": 0,
          "welfare_key": "inequity_aversion_welfare",
          "working_state": "train_selfish"
        }
      ],
      "player_red": [
        "<class 'submission.algos.amTFT.policy_using_rollouts.AmTFTRolloutsTorchPolicy'>",
        "Box(0, 1, (3, 3, 6), uint8)",
        "Discrete(4)",
        {
          "auto_load_checkpoint": true,
          "batch_mode": "complete_episodes",
          "callbacks": null,
          "debit_threshold": 3.0,
          "last_k": 1,
          "n_rollout_replicas": 10,
          "nested_policies": [
            {
              "Policy_class": "<class 'ray.rllib.policy.policy_template.R2D2TorchPolicy'>",
              "config_update": {
                "add_inequity_aversion_welfare": [
                  true,
                  0.0,
                  "<ray.rllib.utils.schedules.piecewise_schedule.PiecewiseSchedule object at 0x7f3684212780>",
                  0.96,
                  0.96
                ],
                "add_utilitarian_welfare": false
              }
            },
            {
              "Policy_class": "<class 'ray.rllib.policy.policy_template.R2D2TorchPolicy'>",
              "config_update": {}
            },
            {
              "Policy_class": "<class 'ray.rllib.policy.policy_template.R2D2TorchPolicy'>",
              "config_update": {}
            },
            {
              "Policy_class": "<class 'ray.rllib.policy.policy_template.R2D2TorchPolicy'>",
              "config_update": {}
            }
          ],
          "opp_policy_id": "player_blue",
          "optimizer": {
            "sgd_momentum": 0.9
          },
          "own_policy_id": "player_red",
          "punish_instead_of_selfish": true,
          "punishment_multiplier": 6.0,
          "rollout_length": 20,
          "use_short_debit_rollout": true,
          "verbose": 0,
          "welfare_key": "inequity_aversion_welfare",
          "working_state": "train_selfish"
        }
      ]
    },
    "policy_mapping_fn": "<function get_rllib_config.<locals>.<lambda> at 0x7f370c572f28>"
  },
  "num_envs_per_worker": 16,
  "num_workers": 0,
  "optimizer": {
    "sgd_momentum": 0.9
  },
  "prioritized_replay": false,
  "rollout_fragment_length": 100,
  "seed": 1621274953,
  "target_network_update_freq": 3000,
  "timesteps_per_iteration": 1600,
  "train_batch_size": 400,
  "training_intensity": 640,
  "use_h_function": false,
  "zero_init_states": false
}